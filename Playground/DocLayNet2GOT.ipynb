{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "train_json = \"/home/t-jiaweiwang/Project/GOT-OCR2.0/datasets/DocLayNet/train_textlines_others_add_text_400_converted_add_in_graphical_others_grouped.json\"\n",
    "\n",
    "train_annotations = json.load(open(train_json))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['images', 'categories', 'annotations'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nConversation Format:\\n\\n{\\n    \"image\": \"image_path\",\\n    \"conversations\": [\\n        {\\n            \"from\": \"human\",\\n            \"value\": \"<image>\\nPOD: \"\\n        },\\n        {\\n            \"from\": \"gpt\",\\n            \"value\": \"[Box1] [Logical Role]\\n[Box2] [Logical Role]\\n...\"\\n        }\\n    ]\\n}\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "Conversation Format:\n",
    "\n",
    "{\n",
    "    \"image\": \"image_path\",\n",
    "    \"conversations\": [\n",
    "        {\n",
    "            \"from\": \"human\",\n",
    "            \"value\": \"<image>\\nPOD: \"\n",
    "        },\n",
    "        {\n",
    "            \"from\": \"gpt\",\n",
    "            \"value\": \"[Box1] [Logical Role]\\n[Box2] [Logical Role]\\n...\"\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "'''\n",
    "\n",
    "conversations = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 1,\n",
       " 'category_id': 4,\n",
       " 'AxisAlignedBBox': [100.1946343137255,\n",
       "  117.51495402298849,\n",
       "  789.325354248366,\n",
       "  42.370593869731806],\n",
       " 'bbox': [100.1946343137255,\n",
       "  117.51495402298849,\n",
       "  789.325354248366,\n",
       "  42.370593869731806,\n",
       "  0],\n",
       " 'quad_coord': [100.1946343137255,\n",
       "  117.51495402298849,\n",
       "  889.5199885620915,\n",
       "  117.51495402298849,\n",
       "  889.5199885620915,\n",
       "  159.8855478927203,\n",
       "  100.1946343137255,\n",
       "  159.8855478927203],\n",
       " 'segmentation': [[100.1946343137255,\n",
       "   117.51495402298849,\n",
       "   100.1946343137255,\n",
       "   159.8855478927203,\n",
       "   889.5199885620915,\n",
       "   159.8855478927203,\n",
       "   889.5199885620915,\n",
       "   117.51495402298849]],\n",
       " 'iscrowd': 0,\n",
       " 'area': 33444.1840159397,\n",
       " 'tags': ['Text'],\n",
       " 'tag_curve': 0,\n",
       " 'tag_notsure': 0,\n",
       " 'textline_polys': [[100.1946343137255,\n",
       "   117.51495402298849,\n",
       "   889.5199885620915,\n",
       "   117.51495402298849,\n",
       "   889.5199885620915,\n",
       "   159.8855478927203,\n",
       "   100.1946343137255,\n",
       "   159.8855478927203]],\n",
       " 'textline_contents': ['Finance receivables that originated outside the U.S. were $52.7 billion and $47.5 billion at December 31, 2004 and 2003, respectively. Other finance receivables consisted primarily of real estate, commercial and other collateralized loans and accrued interest. '],\n",
       " 'textline_logical_roles': [7],\n",
       " 'image_id': 0,\n",
       " 'reading_order_id': 1,\n",
       " 'reading_order_label': 0}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_annotations['annotations'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageid2annotations = {}\n",
    "\n",
    "for annotation in train_annotations[\"annotations\"]:\n",
    "    if annotation[\"image_id\"] not in imageid2annotations:\n",
    "        imageid2annotations[annotation[\"image_id\"]] = []\n",
    "    imageid2annotations[annotation[\"image_id\"]].append(annotation)\n",
    "\n",
    "imageid2image = {}\n",
    "for image in train_annotations[\"images\"]:\n",
    "    imageid2image[image[\"id\"]] = image\n",
    "\n",
    "conversations = []\n",
    "for image_id, annotations in imageid2annotations.items():\n",
    "    image = imageid2image[image_id]\n",
    "    image_path = image[\"file_name\"]\n",
    "    conversation = {\n",
    "        \"image\": \"train/\" + image_path,\n",
    "        \"conversations\": []\n",
    "    }\n",
    "    conversation[\"conversations\"].append({\n",
    "        \"from\": \"human\",\n",
    "        \"value\": \"<image>\\nPOD: \"\n",
    "    })\n",
    "    gt_text = \"\"\n",
    "    gt_boxes = []\n",
    "    gt_logical_roles = []\n",
    "    for annotation in annotations:\n",
    "        bbox = annotation[\"quad_coord\"][:2] + annotation[\"quad_coord\"][4:6]\n",
    "        # x = int(x/w * 1000)\n",
    "        # y = int(y/h * 1000)\n",
    "        bbox = [int(bbox[0] / image[\"width\"] * 1000), int(bbox[1] / image[\"height\"] * 1000), int(bbox[2] / image[\"width\"] * 1000), int(bbox[3] / image[\"height\"] * 1000)]\n",
    "        if \"others\" in annotation[\"tags\"]:\n",
    "            # exclude others\n",
    "            continue\n",
    "        gt_boxes.append(bbox)\n",
    "        gt_logical_roles.append(annotation[\"tags\"][0])\n",
    "\n",
    "    # sort the boxes from top to bottom from left to right\n",
    "    # 将 gt_boxes 和 gt_logical_roles 结合在一起，根据 gt_boxes 进行排序\n",
    "    sorted_pairs = sorted(zip(gt_boxes, gt_logical_roles), key=lambda x: (x[0][1], x[0][0]))\n",
    "    if len(sorted_pairs) == 0:\n",
    "        continue\n",
    "    # 解压缩，提取排序后的 gt_boxes 和 gt_logical_roles\n",
    "    gt_boxes, gt_logical_roles = zip(*sorted_pairs)\n",
    "\n",
    "    # 将它们转换回列表（因为 zip 返回的是元组）\n",
    "    gt_boxes = list(gt_boxes)\n",
    "    gt_logical_roles = list(gt_logical_roles)\n",
    "    \n",
    "    for bbox, logical_role in zip(gt_boxes, gt_logical_roles):\n",
    "        gt_text += f\"{str(bbox)} {logical_role}\\n\"\n",
    "    \n",
    "    conversation[\"conversations\"].append({\n",
    "        \"from\": \"gpt\",\n",
    "        \"value\": gt_text\n",
    "    })\n",
    "    conversations.append(conversation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'conversations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mconversations\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'conversations' is not defined"
     ]
    }
   ],
   "source": [
    "conversations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(conversations, open(\"/home/t-jiaweiwang/Project/GOT-OCR2.0/datasets/DocLayNet/got_annotations/train_got_conversations_wo_others.json\", \"w\"), indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70, 54, 433, 74] Page-header\n",
      "[97, 114, 867, 155] Text\n",
      "[97, 162, 866, 217] Text\n",
      "[97, 223, 861, 278] Text\n",
      "[97, 285, 813, 326] Text\n",
      "[97, 333, 836, 360] Text\n",
      "[94, 361, 891, 473] Table\n",
      "[97, 488, 876, 529] Text\n",
      "[97, 549, 789, 567] Section-header\n",
      "[97, 572, 608, 587] Text\n",
      "[96, 592, 886, 675] Table\n",
      "[97, 687, 886, 742] Text\n",
      "[97, 749, 782, 776] Text\n",
      "[97, 783, 887, 838] Text\n",
      "[924, 963, 947, 979] Page-footer\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可视化GT\n",
    "import json\n",
    "\n",
    "conversations = json.load(open(\"/home/t-jiaweiwang/Project/GOT-OCR2.0/datasets/DocLayNet/got_annotations/train_got_conversations_wo_others.json\"))\n",
    "converstation = conversations[0]\n",
    "image_path = \"/home/t-jiaweiwang/Project/GOT-OCR2.0/datasets/DocLayNet/\" + converstation[\"image\"]\n",
    "outputs = converstation[\"conversations\"][1][\"value\"]\n",
    "print(outputs)\n",
    "outputs_list = outputs.split('\\n')\n",
    "# visualize the bboxes and logical role in args.image_file: [117, 88, 328, 100] ['Section-header']\n",
    "import cv2\n",
    "image_viz = cv2.imread(image_path)\n",
    "w, h = image_viz.shape[1], image_viz.shape[0]\n",
    "for out in outputs_list:\n",
    "    try:\n",
    "        bbox, logical_role = out.split('] ')\n",
    "    except:\n",
    "        continue\n",
    "    bbox = bbox[1:].split(', ')\n",
    "    # bbox = [int(i) for i in bbox]\n",
    "    bbox = [int(i) / 1000 for i in bbox]\n",
    "    bbox = [int(bbox[0]*w), int(bbox[1]*h), int(bbox[2]*w), int(bbox[3]*h)]\n",
    "    if bbox[0] < 0 or bbox[1] < 0 or bbox[2] < 0 or bbox[3] < 0:\n",
    "        continue\n",
    "    image_viz = cv2.rectangle(image_viz, (bbox[0], bbox[1]), (bbox[2], bbox[3]), (0, 255, 0), 2)\n",
    "    image_viz = cv2.putText(image_viz, logical_role, (bbox[0], bbox[1]), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "cv2.imwrite('test_gt.jpg', image_viz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "got",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
